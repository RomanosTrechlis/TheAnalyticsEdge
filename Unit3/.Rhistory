install.packages('neuralnet')
library("neuralnet")
traininginput <-  as.data.frame(runif(50, min=0, max=100))
trainingoutput <- sqrt(traininginput)
#Column bind the data into one variable
trainingdata <- cbind(traininginput,trainingoutput)
colnames(trainingdata) <- c("Input","Output")
View(trainingdata)
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.01)
print(net.sqrt)
plot(net.sqrt)
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=10, threshold=0.001)
print(net.sqrt)
#Plot the neural network
plot(net.sqrt)
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=20, threshold=0.01)
print(net.sqrt)
#Plot the neural network
plot(net.sqrt)
?"neuralnet"
net.sqrt <- neuralnet(Output~Input,trainingdata, hidden=20, rep = 1, threshold=0.01)
print(net.sqrt)
#Plot the neural network
plot(net.sqrt)
?"neuralnet"
testdata <- as.data.frame((1:10)^2) #Generate some squared numbers
net.results <- compute(net.sqrt, testdata)
ls(net.results)
print(net.results$net.result)
#Lets display a better version of the results
cleanoutput <- cbind(testdata,sqrt(testdata),
as.data.frame(net.results$net.result))
colnames(cleanoutput) <- c("Input","Expected Output","Neural Net Output")
print(cleanoutput)
#Train the neural network
#Generate 50 random numbers uniformly distributed between 0 and 100
source('~/.active-rstudio-document')
install.packages("neuralnet")
source('~/.active-rstudio-document')
install.packages('kmeans')
?kmeans
kmeans()
?reshape
?kmeans
df = read.table("../activity.log")
getwd()
df = read.table("../Desktop/activity.log")
df = read.table("../Desktop/logfile.log")
df = read.table("../Desktop/logfile.log", header=T, sep=" ")
df = read.table("../Desktop/logfile.log", header=T, sep="")
df = read.table("../Desktop/logfile.log", header=T, sep=" - ")
df = read.table("../Desktop/logfile.log", header=T, sep=" ")
table(df)
View(df)
View(df)
df = read.table("../Desktop/logfile.log", header=T, sep=",")
View(df)
df = read.table("../Desktop/logfile.log", header=T, sep=",")
df = read.table("../Desktop/logfile.log", header=T, sep=" ")
df = read.table("../Desktop/logfile.log", header=T, sep=" ")
colnames(df)=c("date","time","service","eta")
View(df)
df$datetime = df$date + df$time
library("reshape2")
df$datetime<-melt(df,id.vars=c("date","time"))
require("reshape2")
library.package("reshape2")
df$date=as.Date(df$date,"[%Y%m%d]")
View(df)
df = read.table("../Desktop/logfile.log", header=T, sep=" ")
colnames(df)=c("date","time","service","eta")
df$datetime <- c(df$date, df$time)
View(df)
df$date=as.Date(df$date,"[%Y-%m-%d]")
View(df)
df = read.table("../Desktop/logfile.log", header=T, sep=" ")
colnames(df)=c("date","time","service","eta")
df$date=as.Date(df$date,"[%Y-%M-%D]")
View(df)
df = read.table("../Desktop/logfile.log", header=T, sep=" ")
colnames(df)=c("date","time","service","eta")
df$datetime <- paste(df$date,df$time)
View(df)
ggplot(data=df, aes(x=as.Date(datetime), y=time)) + geom_line() +xlab("Date") + ylab("ETA"))
ggplot(data=df, aes(x=as.Date(datetime), y=time) + geom_line() +xlab("Date") + ylab("ETA"))
library(ggplot2 )
library("ggplot2")
library(ggplot)
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
library(rPython)
install.packages("rPython")
library(rPython)
ggplot(data=df, aes(x=as.Date(datetime), y=time) + geom_line() +xlab("Date") + ylab("ETA"))
install.packages("ggplot2")
library(ggplot2)
sd(c(5,8,12))
which.min(c(4,1,6))
Sys.setlocale("LC_ALL", "C")
View(df)
8*6
2^16
2^
16
2^
8*10
sqrt(4)
sqrt(2)
?sqrt
SquareRoot2 = sqrt(2)
SquareRoot2
SquareRoot2
squareRoot2
HoursYear <- 365*24
HoursYear
ls()
c(2,3,5,8,13)
Country = c("Brazil","China","India","Switcherland", "USA")
LifeExpectancy = c(74,76,65,83,79)
Country
LifeExpectancy
ls()
Country[1]
LifeExpectancy[3]
seq(0,100,2)
#dataframes
CountryData = data.frame(Country, LifeExpectancy)
CountryData
CountryData$Population = c(199000, 1390000, 12400000, 7997, 318000)
CountryData
Country = c("Australia", "Greece")
LifeExpectancy = c(82,81)
Population - c(23050,11125)
Population = c(23050,11125)
NewCountryData = data.frame(Country, LifeExpectancy, Population)
NewCountryData
AllCountryData = rbind(CountryData, NewCountryData)
AllCountryData
summary(AllCountryData)
str(AllCountryData$Population)
str(AllCountryData)
install.packages("caTools")
install.packages("ROCR")
setwd("C:\\Users\\xa86\\Desktop\\Unit3")
quality = read.csv("quality.csv")
str(quality)
library(caTools)
set.seed(88)
split = sample.split(quality$PoorCare, SplitRatio = 0.75)
split
qualityTrain = subset(quality, split == TRUE)
qualityTest = subset(quality, split == FALSE)
QualityLog = glm(PoorCare ~ OfficeVisits + Narcotics, data=qualityTrain, family=binomial)
summary(QualityLog)
predictTrain = predict(QualityLog, type="response")
# Analyze predictions
summary(predictTrain)
tapply(predictTrain, qualityTrain$PoorCare, mean)
Question = glm(PoorCare ~ StartedOnCombination + ProviderCount, data=qualityTrain, family=binomial)
summary(Question)
table(qualityTrain$PoorCare, predictTrain > 0.5)
table(qualityTrain$PoorCare, predictTrain > 0.7)
table(qualityTrain$PoorCare, predictTrain > 0.2)
library(ROCR)
ROCRpred = prediction(predictTrain, qualityTrain$PoorCare)
# Performance function
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf)
plot(ROCRperf, colorize=TRUE)
# Add threshold labels
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
predictTest = predict(QualityLog, type="response", newdata=qualityTest)
ROCRpredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
songs = read.csv("songs.csv")
str(songs)
str(subset(songs, year = 2010))
songs = read.csv("songs.csv")
str(songs)
str(subset(songs, year == 2010))
str(subset(songs, artistname == 'Michael Jackson'))
str(subset(songs, artistname == 'Michael Jackson' & Top10 == 1))
subset(songs, artistname == 'Michael Jackson' & Top10 == 1)
songs = read.csv("songs.csv")
subset(songs, artistname == 'Michael Jackson' & Top10 == 1)$songtitle
str(songs)
table(songs$timesignature)
which.max(songs$tempo)
songs[which.max(songs$tempo),]
songs$songtitle[which.max(songs$tempo)]
SongsTrain = subset(songs, year <= 2009)
SongsTest = subset(songs, year > 2009)
SongsTest = subset(songs, year == 2010)
str(SongsTrain)
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
Model1 = glm(Top10 ~ ., data=SongsTrain, family=binomial)
summary(Model1)
cor(SongsTrain$loudness, SongsTrain$energy)
SongsLog2 = glm(Top10 ~ . - loudness, data=SongsTrain, family=binomial)
summary(SongsLog2)
SongsLog3 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
summary(SongsLog3)
PredLog3 = prediction(SongsLog3, newdata=SongsTest, type="response")
table(SongsTest$Top10, PredLog3 >= 0.45)
PredLog3 = prediction(SongsLog3, newdata=SongsTest, type="response")
# Validating Our Model
PredLog3 = predict(SongsLog3, newdata=SongsTest, type="response")
table(SongsTest$Top10, PredLog3 >= 0.45)
(309 + 19)/(309 + 5 + 40 + 19)
table(SongsTest$Top10)
table(SongsTest$Top10, 0)
59 / (314 + 59)
314 / (314 + 59)
19 / (40 + 19)
309 / (309 + 5)
data = read.csv("parole.csv")
str(data)
table(data$violator)
summary(data$time.served)
table(data$time.served)
table(data$race)
table(data$multiple.offenses)
data$crime = as.factor(data$crime)
data$state = as.factor(data$state)
str(data)
summary()
summary(data)
set.seed(144)
library(caTools)
split = sample.split(parole$violator, SplitRatio = 0.7)
train = subset(parole, split == TRUE)
test = subset(parole, split == FALSE)
set.seed(144)
library(caTools)
split = sample.split(data$violator, SplitRatio = 0.7)
train = subset(data, split == TRUE)
test = subset(data,
split == FALSE)
str(test)
str(train)
model1 = glm(violator ~ ., data=data, family="binomial")
summary(model1)
model1 = glm(violator ~ ., data=train, family="binomial")
summary(model1)
logit = -4.2411574 + 0.3869904 + 0.8867192 + -0.0001756*50 + -0.1238867*3 + 0.0802954*12 + 0.6837143
logit
e^-1.700629
exp(-1.700629)
1/(1+0.1825687)
1/(1+exp(1.700629))
odds=exp(logit)
probability = 1 / (1 + exp(-logit))
odds
probability
pred1 = predict(model1, newdata=test, type="response")
max(pred1)
table(test$violator, pred1 >= 0.5)
sensitivity = 12/(12+11)
specificity = 167/(167+12)
accuracy = (167+12)/(167+12+12+11)
sensitivity
specificity
accuracy
table(test$violator)
179/(179+23)
table(test$violator, pred1 >= 0.7)
table(test$violator, pred1 >= 0.3)
library(ROCR)
ROCRpredTest = prediction(predictTest, qualityTest$PoorCare)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
library(ROCR)
ROCRpredTest = prediction(pred1, test$violator)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
# Preparing the Dataset
loans = read.csv("loans.csv")
str(loans)
table(loans$not.fully.paid)
1533/(1533+8045)
summary(loans)
str(subset(loans, na.omit=TRUE))
table(subset(loans, na.omit=TRUE)$not.fully.paid)
table(subset(loans, na.rm=TRUE)$not.fully.paid)
table(loans$not.fully.paid,loans$revol.util)
table(loans$revol.util)
str(subset(loans, is.na(revol.util)))
str(subset(loans, !is.na(revol.util)))
table(subset(loans, !is.na(revol.util))$not.fully.paid)
1521/(7995/1521)
1521/(7995+1521)
install.packages("mice")
library(mice)
set.seed(144)
vars.for.imputation = setdiff(names(loans), "not.fully.paid")
imputed = complete(mice(loans[vars.for.imputation]))
loans[vars.for.imputation] = imputed
set.seed(144)
library(caTools)
split = sample.split(loans$not.fully.paid, SplitRatio = 0.7)
train = subset(data, split == TRUE)
test = subset(data, split == FALSE)
model1 = glm(not.fully.paid ~ .,data=train, family="binomial")
summary(model1)
model1 = glm(not.fully.paid ~ .,data=train, family="binomial")
train = subset(loans, split == TRUE)
test = subset(loans, split == FALSE)
model1 = glm(not.fully.paid ~ .,data=train, family="binomial")
summary(model1)
logitAminusB = -9.406e-03*700 - -9.406e-03*710
logitAminusB
OddAoverOddB = exp(-9.406e-03*700)/exp(-9.406e-03*710)
OddAoverOddB
pred1 = predict(model1, newdata=test, type="response")
test$predicted.risk = pred1
table(test$predicted.risk)
table(test$predicted.risk, table$not.fully.paid)
table(table$not.fully.paid, test$predicted.risk > 0.5)
str(pred1)
summary(pred1)
table(table$not.fully.paid, pred1 > 0.5)
data.frame(as.list(pred1))
data.frame(pred1)
str(data.frame(pred1))
test$predicted.risk = data.frame(pred1)$pred1
table(table$not.fully.paid, pred1 > 0.5)
test$predicted.risk = data.frame(pred1)$pred1
table(table$not.fully.paid, pred1 > 0.5)
table(test$not.fully.paid, pred1 > 0.5)
(3 + 2400)/(2400+13+457+3)
table(test$not.fully.paid)
2413/(2413+460)
library(ROCR)
ROCRpredTest = prediction(pred1, test$violator)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
ROCRpredTest = prediction(pred1, test$not.fully.paid)
auc = as.numeric(performance(ROCRpredTest, "auc")@y.values)
auc
model2 = glm(not.fully.paid ~ int.rat, data=train, family="binomial")
summary(model1)
model2 = glm(not.fully.paid ~ int.rate, data=train, family="binomial")
summary(model2)
cor(train)
str(train)
vars = c("credit.policy","int.rate","installment","log.annual.inc","dti","fico","days.with.cr.line","revol.bal","revol.util","inq.last.6mths","delinq.2yrs","pub.rec","not.fully.paid")
car(train[vars])
cor(train[vars])
pred2 = predict(model2, newdata=test, type="response")
max(pred2)
table(test$not.fully.paid, pred2 > 0.5)
ROCRpredTest2 = prediction(pred2, test$not.fully.paid)
auc = as.numeric(performance(ROCRpredTest2, "auc")@y.values)
auc
10*exp(0.06*3)
test$profit = exp(test$int.rate*3) - 1
test$profit[test$not.fully.paid == 1] = -1
max(test$profit)
max(test$profit) * 10
sum(test$profit)
test$profit
highIntRates = subset(test, int.rate >= 0.15)
mean(highIntRates$profit)
table(highIntRates$not.fully.paid)
110/327
110/(327+110)
cutoff = sort(highInterest$predicted.risk, decreasing=FALSE)[100]
cutoff = sort(highIntRates$predicted.risk, decreasing=FALSE)[100]
cutoff
selectedLoans = subset(highIntRates, predicted.risk < cutoff)
str(selectedLoans)
str(highIntRates)
selectedLoans = subset(highIntRates, predicted.risk 0< cutoff)
selectedLoans = subset(highIntRates, predicted.risk =< cutoff)
selectedLoans = subset(highIntRates, predicted.risk <= cutoff)
str(selectedLoans)
sum(selectedLoans$profit)
table(selectedLoans$not.fully.paid)
selectedLoans = subset(highIntRates, predicted.risk < cutoff)
str(selectedLoans)
sum(selectedLoans$profit)
table(selectedLoans$not.fully.paid)
18(18+81)
18/(18+81)
